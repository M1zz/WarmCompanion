import Foundation
@preconcurrency import AVFoundation
import Combine

// MARK: - Gemini Multimodal Live API Service
// Ïã§ÏãúÍ∞Ñ ÏñëÎ∞©Ìñ• ÏùåÏÑ± Ïä§Ìä∏Î¶¨Î∞ç: Ïú†Ï†Ä ÏùåÏÑ± ‚Üí [WebSocket] ‚Üí AI ÏùåÏÑ±

// MARK: - WebSocket Delegate (Ïó∞Í≤∞ ÌôïÏù∏Ïö©)
class WebSocketDelegate: NSObject, URLSessionWebSocketDelegate {
    var onOpen: (() -> Void)?
    var onClose: ((URLSessionWebSocketTask.CloseCode, Data?) -> Void)?

    func urlSession(_ session: URLSession, webSocketTask: URLSessionWebSocketTask, didOpenWithProtocol protocol: String?) {
        print("[GeminiLive-WS] didOpen")
        onOpen?()
    }

    func urlSession(_ session: URLSession, webSocketTask: URLSessionWebSocketTask, didCloseWith closeCode: URLSessionWebSocketTask.CloseCode, reason: Data?) {
        print("[GeminiLive-WS] didClose: \(closeCode)")
        onClose?(closeCode, reason)
    }
}

@MainActor
class GeminiLiveService: ObservableObject {

    // MARK: - Session State
    enum SessionState: Equatable {
        case disconnected
        case connecting
        case connected
        case error(String)
    }

    @Published var sessionState: SessionState = .disconnected
    @Published var isModelSpeaking = false
    @Published var inputTranscript = ""
    @Published var outputTranscript = ""
    @Published var isMicMuted = false

    // MARK: - Tunable Parameters (Ïã§ÏãúÍ∞Ñ Ï°∞Ï†à Í∞ÄÎä•)
    @Published var energyThreshold: Float = 0.03          // ÏóêÏΩî Í≤åÏù¥Ìä∏ ÏûÑÍ≥ÑÍ∞í
    @Published var turnCompleteDelayMs: Int = 50           // ÌÑ¥ ÏôÑÎ£å ÌõÑ ÎßàÏù¥ÌÅ¨ Ïó¥Í∏∞ÍπåÏßÄ ÎåÄÍ∏∞(ms)
    @Published var silenceDurationMs: Int = 300            // ÏÑúÎ≤Ñ VAD Ïπ®Î¨µ ÌåêÎã® Í∏∞Ï§Ä(ms)
    @Published var startSensitivity: String = "START_SENSITIVITY_HIGH"  // Î∞úÌôî ÏãúÏûë Í∞êÎèÑ
    @Published var endSensitivity: String = "END_SENSITIVITY_LOW"       // Î∞úÌôî Ï¢ÖÎ£å Í∞êÎèÑ

    // MARK: - Debug Metrics (Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ)
    @Published var debugCurrentRMS: Float = 0              // ÌòÑÏû¨ ÎßàÏù¥ÌÅ¨ ÏóêÎÑàÏßÄ
    @Published var debugLastResponseLatencyMs: Int = 0     // ÎßàÏßÄÎßâ ÏùëÎãµ ÏßÄÏó∞(ms)
    @Published var debugTurnCount: Int = 0                 // Ï¥ù ÌÑ¥ Ïàò
    @Published var debugInterruptCount: Int = 0            // Ïù∏ÌÑ∞ÎüΩÌä∏ ÌöüÏàò
    @Published var debugDroppedAudioCount: Int = 0         // Î¨¥ÏãúÎêú Ïò§ÎîîÏò§ Ï≤≠ÌÅ¨ Ïàò
    @Published var debugIsEchoGated: Bool = false          // ÏóêÏΩî Í≤åÏù¥Ìä∏ ÌôúÏÑ± Ïó¨Î∂Ä
    private var responseLatenies: [Int] = []               // ÏùëÎãµ ÏßÄÏó∞ ÎàÑÏ†Å (ÌèâÍ∑† Í≥ÑÏÇ∞Ïö©)
    var debugAvgResponseLatencyMs: Int {                    // ÌèâÍ∑† ÏùëÎãµ ÏßÄÏó∞
        responseLatenies.isEmpty ? 0 : responseLatenies.reduce(0, +) / responseLatenies.count
    }

    // MARK: - Callback
    var onConversationTurn: ((String, String) -> Void)?

    // MARK: - Private
    private var webSocketTask: URLSessionWebSocketTask?
    private var urlSession: URLSession?
    private var wsDelegate: WebSocketDelegate?
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var playerMixer: AVAudioMixerNode?
    private var systemPrompt = ""
    private var memoryContext = ""
    private var sessionTimer: Timer?
    private var pendingAudioBuffers: [Data] = []
    private var isReceivingAudio = false
    private var reconnectAttempts = 0
    private let maxReconnectAttempts = 3

    private var currentInputText = ""
    private var currentOutputText = ""
    private var turnCompleteTask: Task<Void, Never>?
    private var modelTurnId: UInt64 = 0        // ÌòÑÏû¨ Î™®Îç∏ ÌÑ¥ ÏãùÎ≥ÑÏûê (Í≤πÏπ® Î∞©ÏßÄ)
    private var isInterrupted = false           // Ïù∏ÌÑ∞ÎüΩÌä∏ ÌõÑ ÏûîÏó¨ Ïò§ÎîîÏò§ Î¨¥ÏãúÏö©
    private var userSpeechEndTime: CFAbsoluteTime = 0  // ÏÇ¨Ïö©Ïûê Î∞úÌôî Ï¢ÖÎ£å ÏãúÏ†ê (ÏùëÎãµ ÏßÄÏó∞ Ï∏°Ï†ï)

    private let inputSampleRate: Double = 16000
    private let outputSampleRate: Double = 24000

    // MARK: - Configure
    func configure(systemPrompt: String, memoryContext: String) {
        self.systemPrompt = systemPrompt
        self.memoryContext = memoryContext
    }

    func updateMemoryContext(_ context: String) {
        self.memoryContext = context
    }

    // MARK: - Connect
    func connect() {
        guard sessionState != .connecting, sessionState != .connected else { return }
        sessionState = .connecting

        let urlString = "\(APIConfig.geminiLiveWebSocketURL)?key=\(APIConfig.geminiAPIKey)"
        guard let url = URL(string: urlString) else {
            sessionState = .error("Invalid WebSocket URL")
            return
        }

        // DelegateÎ°ú Ïó∞Í≤∞ ÌôïÏù∏
        let delegate = WebSocketDelegate()
        self.wsDelegate = delegate

        delegate.onOpen = { [weak self] in
            Task { @MainActor in
                guard let self = self else { return }
                print("[GeminiLive] ‚úÖ WebSocket Ïó∞Í≤∞Îê® - setup Ï†ÑÏÜ°")
                self.reconnectAttempts = 0
                self.sendSetupMessage()
                self.startReceiving()
                self.startSessionTimer()
            }
        }

        delegate.onClose = { [weak self] closeCode, reason in
            Task { @MainActor in
                guard let self = self else { return }
                let reasonStr = reason.flatMap { String(data: $0, encoding: .utf8) } ?? "unknown"
                print("[GeminiLive] ‚ùå WebSocket Îã´Ìûò: \(closeCode) reason: \(reasonStr)")
                if self.sessionState == .connected || self.sessionState == .connecting {
                    self.sessionState = .error("Ïó∞Í≤∞ ÎÅäÍπÄ")
                    self.attemptReconnect()
                }
            }
        }

        let session = URLSession(configuration: .default, delegate: delegate, delegateQueue: nil)
        self.urlSession = session

        let task = session.webSocketTask(with: url)
        self.webSocketTask = task
        task.resume()

        print("[GeminiLive] WebSocket Ïó∞Í≤∞ ÏãúÏûë: \(url.host ?? "")")
    }

    // MARK: - Disconnect
    func disconnect() {
        print("[GeminiLive] Ïó∞Í≤∞ Ï¢ÖÎ£å")
        sessionTimer?.invalidate()
        sessionTimer = nil

        stopAudioEngine()
        stopPlayback()

        webSocketTask?.cancel(with: .normalClosure, reason: nil)
        webSocketTask = nil
        wsDelegate = nil
        urlSession?.invalidateAndCancel()
        urlSession = nil

        sessionState = .disconnected
        isModelSpeaking = false
        isMicMuted = false
        inputTranscript = ""
        outputTranscript = ""
        currentInputText = ""
        currentOutputText = ""
        pendingAudioBuffers = []
        reconnectAttempts = 0
        modelTurnId = 0
        isInterrupted = false
        userSpeechEndTime = 0
        turnCompleteTask?.cancel()
        turnCompleteTask = nil
        debugCurrentRMS = 0
        debugLastResponseLatencyMs = 0
        debugTurnCount = 0
        debugInterruptCount = 0
        debugDroppedAudioCount = 0
        debugIsEchoGated = false
        responseLatenies = []
    }

    // MARK: - Mic Mute
    func setMicMuted(_ muted: Bool) {
        isMicMuted = muted
        print("[GeminiLive] ÎßàÏù¥ÌÅ¨ ÏùåÏÜåÍ±∞: \(muted)")
    }

    // MARK: - Setup Message
    private func sendSetupMessage() {
        let fullPrompt = systemPrompt + memoryContext +
            "\n\n## ÌÜµÌôî Î™®Îìú Ï∂îÍ∞Ä ÏßÄÏπ®\n- ÏßÄÍ∏àÏùÄ Ï†ÑÌôî ÌÜµÌôî Ï§ëÏù¥Ïïº. ÏßßÍ≥† ÏûêÏó∞Ïä§ÎüΩÍ≤å ÎßêÌï¥.\n- 1~2Î¨∏Ïû• Ïù¥ÎÇ¥Î°ú ÏßßÍ≤å ÎãµÌï¥. Í∏∏Í≤å ÎßêÌïòÏßÄ Îßà.\n- ÏÉÅÎåÄÎ∞©Ïù¥ ÎßêÌïòÎ©¥ Ï¶âÏãú Î∞òÏùëÌï¥. ÏÉùÍ∞ÅÌïòÎäî ÏãúÍ∞Ñ ÏóÜÏù¥ Î∞îÎ°ú ÎåÄÎãµÌï¥.\n- Ïπ®Î¨µÏù¥ ÏÉùÍ∏∞Î©¥ ÏûêÏó∞Ïä§ÎüΩÍ≤å Î®ºÏ†Ä ÎßêÏùÑ Í±∏Ïñ¥Ï§ò. 'Î≠ê Ìï¥?', 'Îòê Î¨¥Ïä® ÏñòÍ∏∞ Ìï†Íπå?' Í∞ôÏù¥.\n- ÎåÄÎãµÌï† Îïå 'Ïùå...', 'Í∑∏Îü¨ÎãàÍπå...' Í∞ôÏùÄ Î®∏Î≠áÍ±∞Î¶º ÏóÜÏù¥ Î∞îÎ°ú ÌïµÏã¨ÏùÑ ÎßêÌï¥.\n- ÌÜµÌôîÍ∞Ä ÏãúÏûëÎêòÎ©¥ Î∞òÎìúÏãú 'Ïó¨Î≥¥ÏÑ∏Ïöî?' ÎùºÍ≥† Î®ºÏ†Ä Ïù∏ÏÇ¨Ìï¥. Ï≤´ ÎßàÎîîÎäî Ìï≠ÏÉÅ 'Ïó¨Î≥¥ÏÑ∏Ïöî?'Ïïº."

        let setup: [String: Any] = [
            "setup": [
                "model": APIConfig.geminiLiveModel,
                "generationConfig": [
                    "responseModalities": ["AUDIO"],
                    "speechConfig": [
                        "voiceConfig": [
                            "prebuiltVoiceConfig": [
                                "voiceName": APIConfig.geminiLiveVoice
                            ]
                        ],
                        "languageCode": "ko-KR"
                    ]
                ],
                "systemInstruction": [
                    "parts": [["text": fullPrompt]]
                ],
                "realtimeInputConfig": [
                    "automaticActivityDetection": [
                        "disabled": false,
                        "startOfSpeechSensitivity": startSensitivity,
                        "endOfSpeechSensitivity": endSensitivity,
                        "prefixPaddingMs": 20,
                        "silenceDurationMs": silenceDurationMs
                    ]
                ],
                "inputAudioTranscription": [String: Any](),
                "outputAudioTranscription": [String: Any]()
            ]
        ]

        sendJSON(setup)
    }

    // MARK: - Send JSON
    private func sendJSON(_ dict: [String: Any]) {
        guard let data = try? JSONSerialization.data(withJSONObject: dict),
              let str = String(data: data, encoding: .utf8) else {
            print("[GeminiLive] JSON ÏßÅÎ†¨Ìôî Ïã§Ìå®")
            return
        }
        print("[GeminiLive] Ï†ÑÏÜ°: \(str.prefix(200))...")
        webSocketTask?.send(.string(str)) { error in
            if let error = error {
                print("[GeminiLive] Ï†ÑÏÜ° ÏóêÎü¨: \(error.localizedDescription)")
            }
        }
    }

    // MARK: - Initial Greeting (AIÍ∞Ä Î®ºÏ†Ä "Ïó¨Î≥¥ÏÑ∏Ïöî?" Î∞úÌôî)
    private func sendInitialGreeting() {
        let greeting: [String: Any] = [
            "clientContent": [
                "turns": [
                    [
                        "role": "user",
                        "parts": [["text": "(Ï†ÑÌôîÍ∞Ä Ïó∞Í≤∞ÎêòÏóàÏñ¥. Î®ºÏ†Ä Ïó¨Î≥¥ÏÑ∏Ïöî? ÌïòÍ≥† Ïù∏ÏÇ¨Ìï¥Ï§ò)"]]
                    ]
                ],
                "turnComplete": true
            ]
        ]
        print("[GeminiLive] üó£Ô∏è Ï¥àÍ∏∞ Ïù∏ÏÇ¨ ÏöîÏ≤≠ Ï†ÑÏÜ°")
        sendJSON(greeting)
    }

    // MARK: - Send Audio
    private func sendAudioChunk(_ base64Audio: String) {
        let msg: [String: Any] = [
            "realtimeInput": [
                "mediaChunks": [
                    [
                        "mimeType": "audio/pcm;rate=16000",
                        "data": base64Audio
                    ]
                ]
            ]
        ]
        sendJSON(msg)
    }

    // MARK: - Receive Messages
    private func startReceiving() {
        webSocketTask?.receive { [weak self] result in
            Task { @MainActor in
                guard let self = self else { return }
                switch result {
                case .success(let message):
                    switch message {
                    case .string(let text):
                        self.handleServerMessage(text)
                    case .data(let data):
                        if let text = String(data: data, encoding: .utf8) {
                            self.handleServerMessage(text)
                        }
                    @unknown default:
                        break
                    }
                    self.startReceiving()

                case .failure(let error):
                    print("[GeminiLive] ÏàòÏã† ÏóêÎü¨: \(error.localizedDescription)")
                    // delegate.onCloseÍ∞Ä Ï≤òÎ¶¨ÌïòÎØÄÎ°ú Ïó¨Í∏∞ÏÑúÎäî Î°úÍ∑∏Îßå
                }
            }
        }
    }

    // MARK: - Handle Server Messages
    private func handleServerMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            print("[GeminiLive] JSON ÌååÏã± Ïã§Ìå®: \(text.prefix(100))")
            return
        }

        // setupComplete
        if json["setupComplete"] != nil {
            print("[GeminiLive] ‚úÖ Setup complete - ÏÑ∏ÏÖò ÌôúÏÑ±Ìôî")
            sessionState = .connected
            startAudioEngine()
            sendInitialGreeting()
            return
        }

        // goAway
        if json["goAway"] != nil {
            print("[GeminiLive] ‚ö†Ô∏è goAway ÏàòÏã† - Ïû¨Ïó∞Í≤∞ ÏòàÏ†ï")
            attemptReconnect()
            return
        }

        // serverContent
        if let serverContent = json["serverContent"] as? [String: Any] {
            handleServerContent(serverContent)
            return
        }

        print("[GeminiLive] ÎØ∏Ï≤òÎ¶¨ Î©îÏãúÏßÄ: \(text.prefix(200))")
    }

    private func handleServerContent(_ content: [String: Any]) {
        // interrupted - ÏÇ¨Ïö©ÏûêÍ∞Ä ÎÅºÏñ¥Îì§ÏóàÏùÑ Îïå Ï¶âÏãú Ïû¨ÏÉù Ï§ëÎã® + ÎßàÏù¥ÌÅ¨ Ïó¥Í∏∞
        if content["interrupted"] as? Bool == true {
            print("[GeminiLive] üîá Interrupted - Ïû¨ÏÉù Ï¶âÏãú Ï§ëÎã®")
            debugInterruptCount += 1
            turnCompleteTask?.cancel()
            isInterrupted = true          // Ïù¥ÌõÑ ÎèÑÏ∞©ÌïòÎäî Ïù¥Ï†Ñ ÌÑ¥ Ïò§ÎîîÏò§ Î¨¥Ïãú
            stopPlayback()
            isModelSpeaking = false
            isReceivingAudio = false
            return
        }

        // modelTurn
        if let modelTurn = content["modelTurn"] as? [String: Any],
           let parts = modelTurn["parts"] as? [[String: Any]] {

            // Ïù∏ÌÑ∞ÎüΩÌä∏ ÌõÑ ÏûîÏó¨ Ïò§ÎîîÏò§ Î¨¥Ïãú (turnComplete Ï†ÑÍπåÏßÄ)
            if isInterrupted {
                debugDroppedAudioCount += 1
                print("[GeminiLive] ‚è≠Ô∏è Ïù∏ÌÑ∞ÎüΩÌä∏ ÌõÑ ÏûîÏó¨ Ïò§ÎîîÏò§ Î¨¥Ïãú (drop #\(debugDroppedAudioCount))")
                return
            }

            for part in parts {
                if let inlineData = part["inlineData"] as? [String: Any],
                   let audioBase64 = inlineData["data"] as? String {
                    if !isModelSpeaking {
                        // ÏÉà ÌÑ¥ ÏãúÏûë: Ïù¥Ï†Ñ Ïû¨ÏÉùÏùÑ ÌôïÏã§Ìûà Ï†ïÎ¶¨ÌïòÍ≥† ÏÉà ÌÑ¥ ID Î∞úÍ∏â
                        stopPlayback()
                        modelTurnId += 1
                        debugTurnCount += 1
                        isModelSpeaking = true
                        isReceivingAudio = true
                        // ÏùëÎãµ ÏßÄÏó∞ Ï∏°Ï†ï
                        if userSpeechEndTime > 0 {
                            let latency = Int((CFAbsoluteTimeGetCurrent() - userSpeechEndTime) * 1000)
                            debugLastResponseLatencyMs = latency
                            responseLatenies.append(latency)
                            print("[GeminiLive] üîä ÏÉà Î™®Îç∏ ÌÑ¥ ÏãúÏûë (id: \(modelTurnId), ÏùëÎãµÏßÄÏó∞: \(latency)ms, ÌèâÍ∑†: \(debugAvgResponseLatencyMs)ms)")
                        } else {
                            print("[GeminiLive] üîä ÏÉà Î™®Îç∏ ÌÑ¥ ÏãúÏûë (id: \(modelTurnId))")
                        }
                    }
                    if let audioData = Data(base64Encoded: audioBase64) {
                        playAudioData(audioData, forTurnId: modelTurnId)
                    }
                }
                if let textPart = part["text"] as? String {
                    currentOutputText += textPart
                    outputTranscript = currentOutputText
                }
            }
        }

        // turnComplete
        if content["turnComplete"] as? Bool == true {
            print("[GeminiLive] ‚úÖ Turn complete")
            isReceivingAudio = false
            isInterrupted = false  // ÌÑ¥ Í≤ΩÍ≥ÑÏóêÏÑú Ïù∏ÌÑ∞ÎüΩÌä∏ ÌîåÎûòÍ∑∏ Î¶¨ÏÖã

            // Ïù¥Ï†Ñ ÎåÄÍ∏∞ ÌÉÄÏä§ÌÅ¨Í∞Ä ÏûàÏúºÎ©¥ Ï∑®ÏÜå
            turnCompleteTask?.cancel()
            turnCompleteTask = Task {
                // ÌäúÎãù Í∞ÄÎä•Ìïú ÎåÄÍ∏∞ ÏãúÍ∞Ñ ÌõÑ ÎßàÏù¥ÌÅ¨ ÌôúÏÑ±Ìôî
                let delayNs = UInt64(self.turnCompleteDelayMs) * 1_000_000
                try? await Task.sleep(nanoseconds: delayNs)
                if !Task.isCancelled, !self.isReceivingAudio {
                    self.isModelSpeaking = false
                }
            }

            if !currentInputText.isEmpty || !currentOutputText.isEmpty {
                let input = currentInputText
                let output = currentOutputText
                onConversationTurn?(input, output)
            }
            currentInputText = ""
            currentOutputText = ""
        }

        // inputAudioTranscription
        if let inputTranscription = content["inputAudioTranscription"] as? [String: Any],
           let text = inputTranscription["text"] as? String {
            currentInputText += text
            inputTranscript = currentInputText
            userSpeechEndTime = CFAbsoluteTimeGetCurrent()  // ÏùëÎãµ ÏßÄÏó∞ Ï∏°Ï†ï Í∏∞Ï§ÄÏ†ê
            print("[GeminiLive] üé§ Input: \(text)")
        }

        // outputAudioTranscription
        if let outputTranscription = content["outputAudioTranscription"] as? [String: Any],
           let text = outputTranscription["text"] as? String {
            currentOutputText += text
            outputTranscript = currentOutputText
            print("[GeminiLive] üîä Output: \(text)")
        }
    }

    // MARK: - Audio Engine (Input)
    private func startAudioEngine() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetoothHFP])
            try audioSession.setActive(true)
        } catch {
            print("[GeminiLive] Ïò§ÎîîÏò§ ÏÑ∏ÏÖò ÏÑ§Ï†ï Ïã§Ìå®: \(error)")
            sessionState = .error("Ïò§ÎîîÏò§ ÏÑ∏ÏÖò ÏÑ§Ï†ï Ïã§Ìå®")
            return
        }

        let engine = AVAudioEngine()
        let player = AVAudioPlayerNode()
        let mixer = AVAudioMixerNode()

        engine.attach(player)
        engine.attach(mixer)

        let outputFormat = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: outputSampleRate, channels: 1, interleaved: true)!
        engine.connect(player, to: mixer, format: outputFormat)
        engine.connect(mixer, to: engine.mainMixerNode, format: nil)

        let inputNode = engine.inputNode
        let inputHWFormat = inputNode.outputFormat(forBus: 0)
        print("[GeminiLive] ÏûÖÎ†• HW Ìè¨Îß∑: \(inputHWFormat)")

        let targetFormat = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: inputSampleRate, channels: 1, interleaved: true)!
        let converter: AVAudioConverter? = AVAudioConverter(from: inputHWFormat, to: targetFormat)
        if converter == nil {
            print("[GeminiLive] ‚ö†Ô∏è Ïò§ÎîîÏò§ Î≥ÄÌôòÍ∏∞ ÏÉùÏÑ± Ïã§Ìå®")
        }

        inputNode.installTap(onBus: 0, bufferSize: 4096, format: inputHWFormat) { [weak self] buffer, _ in
            guard let self = self, !self.isMicMuted else { return }

            // ÏóêÎÑàÏßÄ Ï∏°Ï†ï (ÎîîÎ≤ÑÍ∑∏ Î©îÌä∏Î¶≠)
            let energy = self.calculateRMS(buffer: buffer)
            Task { @MainActor in
                self.debugCurrentRMS = energy
            }

            // AI Î∞úÌôî Ï§ëÏóêÎäî ÏóêÎÑàÏßÄ Ï≤¥ÌÅ¨Î°ú ÏóêÏΩî ÌïÑÌÑ∞ÎßÅ (Ïä§ÌîºÏª§ ‚Üí ÎßàÏù¥ÌÅ¨ ÌîºÎìúÎ∞± Î∞©ÏßÄ)
            // .voiceChat Î™®ÎìúÏùò HW ÏóêÏΩî Ï†úÍ±∞ + SW ÏóêÎÑàÏßÄ Í≤åÏù¥Ìä∏ Ïù¥Ï§ë Î≥¥Ìò∏
            if self.isModelSpeaking {
                let threshold = self.energyThreshold
                guard energy > threshold else {
                    Task { @MainActor in self.debugIsEchoGated = true }
                    return
                }
                Task { @MainActor in self.debugIsEchoGated = false }
                print("[GeminiLive] üé§ ÏÇ¨Ïö©Ïûê ÎÅºÏñ¥Îì§Í∏∞ Í∞êÏßÄ (energy: \(String(format: "%.4f", energy)), threshold: \(threshold))")
            } else {
                Task { @MainActor in self.debugIsEchoGated = false }
            }

            guard let pcmBuffer = self.convertBuffer(buffer, from: inputHWFormat, to: targetFormat, converter: converter) else {
                return
            }

            let frameLength = Int(pcmBuffer.frameLength)
            guard frameLength > 0, let channelData = pcmBuffer.int16ChannelData else { return }

            let data = Data(bytes: channelData[0], count: frameLength * 2)
            let base64 = data.base64EncodedString()

            Task { @MainActor in
                self.sendAudioChunk(base64)
            }
        }

        do {
            engine.prepare()
            try engine.start()
            print("[GeminiLive] üéôÔ∏è Ïò§ÎîîÏò§ ÏóîÏßÑ ÏãúÏûë")
        } catch {
            print("[GeminiLive] Ïò§ÎîîÏò§ ÏóîÏßÑ ÏãúÏûë Ïã§Ìå®: \(error)")
            sessionState = .error("Ïò§ÎîîÏò§ ÏóîÏßÑ ÏãúÏûë Ïã§Ìå®")
            return
        }

        self.audioEngine = engine
        self.playerNode = player
        self.playerMixer = mixer
    }

    // MARK: - Audio Energy (ÏóêÏΩî vs Ïã§Ï†ú ÏùåÏÑ± Íµ¨Î∂Ñ)
    /// ÎßàÏù¥ÌÅ¨ ÏûÖÎ†•Ïùò RMS ÏóêÎÑàÏßÄ Í≥ÑÏÇ∞ (Ïò§ÎîîÏò§ Ïä§Î†àÎìúÏóêÏÑú Ìò∏Ï∂ú)
    private nonisolated func calculateRMS(buffer: AVAudioPCMBuffer) -> Float {
        guard let channelData = buffer.floatChannelData else { return 0 }
        let count = Int(buffer.frameLength)
        guard count > 0 else { return 0 }
        var sumOfSquares: Float = 0
        let ptr = channelData[0]
        for i in 0..<count {
            let sample = ptr[i]
            sumOfSquares += sample * sample
        }
        return sqrt(sumOfSquares / Float(count))
    }

    private func convertBuffer(_ buffer: AVAudioPCMBuffer, from sourceFormat: AVAudioFormat, to targetFormat: AVAudioFormat, converter: AVAudioConverter?) -> AVAudioPCMBuffer? {
        guard let converter = converter else { return nil }

        let ratio = targetFormat.sampleRate / sourceFormat.sampleRate
        let outputFrameCapacity = AVAudioFrameCount(Double(buffer.frameLength) * ratio) + 1
        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: outputFrameCapacity) else { return nil }

        var error: NSError?
        var consumed = false
        converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            if consumed {
                outStatus.pointee = .noDataNow
                return nil
            }
            consumed = true
            outStatus.pointee = .haveData
            return buffer
        }

        if let error = error {
            print("[GeminiLive] Î≥ÄÌôò ÏóêÎü¨: \(error)")
            return nil
        }
        return outputBuffer
    }

    private func stopAudioEngine() {
        audioEngine?.inputNode.removeTap(onBus: 0)
        playerNode?.stop()
        audioEngine?.stop()
        audioEngine = nil
        playerNode = nil
        playerMixer = nil
    }

    // MARK: - Audio Playback (Output)
    private func playAudioData(_ data: Data, forTurnId turnId: UInt64) {
        // Ïù¥ÎØ∏ ÏßÄÎÇòÍ∞Ñ ÌÑ¥Ïùò Ïò§ÎîîÏò§Îäî Ïû¨ÏÉùÌïòÏßÄ ÏïäÏùå (Í≤πÏπ® Î∞©ÏßÄ)
        guard turnId == modelTurnId else {
            print("[GeminiLive] ‚è≠Ô∏è Ïù¥Ï†Ñ ÌÑ¥(\(turnId)) Ïò§ÎîîÏò§ Î¨¥Ïãú (ÌòÑÏû¨: \(modelTurnId))")
            return
        }

        guard let playerNode = playerNode,
              let engine = audioEngine,
              engine.isRunning else { return }

        let format = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: outputSampleRate, channels: 1, interleaved: true)!
        let frameCount = UInt32(data.count / 2)

        guard frameCount > 0,
              let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else { return }

        buffer.frameLength = frameCount
        data.withUnsafeBytes { rawPtr in
            if let src = rawPtr.baseAddress {
                memcpy(buffer.int16ChannelData![0], src, data.count)
            }
        }

        if !playerNode.isPlaying {
            playerNode.play()
        }
        playerNode.scheduleBuffer(buffer)
    }

    private func stopPlayback() {
        // stop()ÏùÄ Ïä§ÏºÄÏ§ÑÎêú Î≤ÑÌçºÎèÑ Î™®Îëê Ï†úÍ±∞Ìï®
        playerNode?.stop()
        pendingAudioBuffers = []
    }

    // MARK: - Session Timer (14-min reconnect)
    private func startSessionTimer() {
        sessionTimer?.invalidate()
        sessionTimer = Timer.scheduledTimer(withTimeInterval: 14 * 60, repeats: false) { [weak self] _ in
            Task { @MainActor in
                print("[GeminiLive] ‚è∞ 14Î∂Ñ ÏÑ∏ÏÖò ÌÉÄÏù¥Î®∏ - Ïû¨Ïó∞Í≤∞")
                self?.attemptReconnect()
            }
        }
    }

    private func attemptReconnect() {
        reconnectAttempts += 1
        guard reconnectAttempts <= maxReconnectAttempts else {
            print("[GeminiLive] ‚ùå ÏµúÎåÄ Ïû¨Ïó∞Í≤∞ ÌöüÏàò Ï¥àÍ≥º (\(maxReconnectAttempts)Ìöå)")
            sessionState = .error("Ïó∞Í≤∞ Ïã§Ìå® - Ïû¨ÏãúÎèÑ ÌöüÏàò Ï¥àÍ≥º")
            return
        }

        print("[GeminiLive] üîÑ Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ \(reconnectAttempts)/\(maxReconnectAttempts)")
        let savedPrompt = systemPrompt
        let savedMemory = memoryContext
        let savedCallback = onConversationTurn
        let attempts = reconnectAttempts

        disconnect()

        Task {
            let delay = UInt64(attempts) * 2_000_000_000 // Ï†êÏßÑÏ†Å ÎîúÎ†àÏù¥
            try? await Task.sleep(nanoseconds: delay)
            self.systemPrompt = savedPrompt
            self.memoryContext = savedMemory
            self.onConversationTurn = savedCallback
            self.reconnectAttempts = attempts
            self.connect()
        }
    }
}
